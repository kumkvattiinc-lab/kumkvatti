{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpuPPGiknohH5r8fXKIqZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumkvattiinc-lab/kumkvatti/blob/main/Untitled27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3Sa85Lf-VXW",
        "outputId": "c0bb0b22-91fc-46cb-8339-9061fbb8b0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  stage1_individual_data.zip\n",
            "  inflating: book_descriptions.csv   \n",
            "  inflating: book_genres.csv         \n",
            "  inflating: books.csv               \n",
            "  inflating: genres.csv              \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n",
            "  inflating: users.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip stage1_individual_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "def load_data():\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    return train, test\n",
        "\n",
        "def create_features(train, test):\n",
        "    user_stats = train.groupby('user_id')['rating'].agg(['mean', 'std', 'count', 'min', 'max']).fillna(0)\n",
        "    user_stats.columns = ['user_mean', 'user_std', 'user_count', 'user_min', 'user_max']\n",
        "    user_stats['user_range'] = user_stats['user_max'] - user_stats['user_min']\n",
        "\n",
        "    for col in user_stats.columns:\n",
        "        train[col] = train['user_id'].map(user_stats[col]).fillna(0)\n",
        "        test[col] = test['user_id'].map(user_stats[col]).fillna(0)\n",
        "\n",
        "    book_stats = train.groupby('book_id')['rating'].agg(['mean', 'std', 'count', 'min', 'max']).fillna(0)\n",
        "    book_stats.columns = ['book_mean', 'book_std', 'book_count', 'book_min', 'book_max']\n",
        "    book_stats['book_range'] = book_stats['book_max'] - book_stats['book_min']\n",
        "\n",
        "    for col in book_stats.columns:\n",
        "        train[col] = train['book_id'].map(book_stats[col]).fillna(0)\n",
        "        test[col] = test['book_id'].map(book_stats[col]).fillna(0)\n",
        "\n",
        "    train['user_book_diff'] = train['user_mean'] - train['book_mean']\n",
        "    train['user_book_avg'] = (train['user_mean'] + train['book_mean']) / 2\n",
        "    test['user_book_diff'] = test['user_mean'] - test['book_mean']\n",
        "    test['user_book_avg'] = (test['user_mean'] + test['book_mean']) / 2\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def prepare_data(train, test):\n",
        "    train = train[train['has_read'] == 1].copy()\n",
        "    train, test = create_features(train, test)\n",
        "\n",
        "    feature_cols = [col for col in train.columns\n",
        "                   if col not in ['user_id', 'book_id', 'rating', 'has_read', 'timestamp', 'Unnamed: 0']\n",
        "                   and train[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "    X_train = train[feature_cols].fillna(0).values\n",
        "    y_train = train['rating'].values\n",
        "    X_test = test[feature_cols].fillna(0).values\n",
        "\n",
        "    return X_train, y_train, X_test, feature_cols, train['user_id'].values\n",
        "\n",
        "def train_model(X_train, y_train, X_test, groups, feature_cols):\n",
        "    oof_predictions = np.zeros(len(X_train))\n",
        "    test_predictions = np.zeros(len(X_test))\n",
        "    models = []\n",
        "\n",
        "    gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train, y_train, groups)):\n",
        "        X_fold_train = X_train[train_idx]\n",
        "        y_fold_train = y_train[train_idx]\n",
        "        X_fold_val = X_train[val_idx]\n",
        "\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=20,\n",
        "            min_samples_split=5,\n",
        "            min_samples_leaf=2,\n",
        "            max_features='sqrt',\n",
        "            bootstrap=True,\n",
        "            random_state=42 + fold,\n",
        "            n_jobs=-1,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        model.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "        y_val_pred = model.predict(X_fold_val)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        oof_predictions[val_idx] = y_val_pred\n",
        "        test_predictions += y_test_pred / 5\n",
        "        models.append(model)\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    feature_importance = np.zeros(len(feature_cols))\n",
        "    for model in models:\n",
        "        feature_importance += model.feature_importances_\n",
        "    feature_importance /= len(models)\n",
        "\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_cols,\n",
        "        'importance': feature_importance\n",
        "    })\n",
        "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
        "    importance_df.to_csv('feature_importance.csv', index=False)\n",
        "\n",
        "    with open('models.pkl', 'wb') as f:\n",
        "        pickle.dump(models, f)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_train, oof_predictions))\n",
        "\n",
        "    return test_predictions, models, importance_df, oof_predictions, rmse\n",
        "\n",
        "def create_submission(test, predictions):\n",
        "    submission = test[['user_id', 'book_id']].copy()\n",
        "    predictions = np.clip(predictions, 0.0, 10.0)\n",
        "    submission['rating_predict'] = predictions\n",
        "    submission.to_csv('submission.csv', index=False, float_format='%.6f')\n",
        "    return submission\n",
        "\n",
        "def main():\n",
        "    train, test = load_data()\n",
        "    X_train, y_train, X_test, feature_cols, groups = prepare_data(train, test)\n",
        "    test_predictions, models, importance_df, oof_predictions, rmse = train_model(X_train, y_train, X_test, groups, feature_cols)\n",
        "    create_submission(test, test_predictions)\n",
        "\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9EsyQs1-eS2",
        "outputId": "c8d76560-5639-4b90-dbcf-1fc8bf4673b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2.0740\n"
          ]
        }
      ]
    }
  ]
}